# Deep Visuals
Generation of content is an interesting and challenging field in machine learning. Many models architectures have been proposed for the goal of generating images, text, video and audio.

In this project, audio embeddings are combined with a conditioned video diffusion model to produce visuals conditioned on music.

Sample output - https://drive.google.com/file/d/1dPEo4x0UQYO4tbSiEW2TJfBEpJXYB8Zn/view?usp=sharing

# Dataset
A collection of Youtube music visual videos split into 5 second chunks.
